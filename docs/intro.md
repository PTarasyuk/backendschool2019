# Введение

## Кратко о том, что будем делать?

Представим, что интернет-магазин подарков планирует запустить акцию в разных регионах. Чтобы стратегия продаж была эффективной, необходим анализ рынка. У магазина есть поставщик, регулярно присылающий (например, на почту) выгрузки данных с информацией о жителях.

Давайте разработаем REST API-сервис на Python, который будет анализировать предоставленные данные и выявлять спрос на подарки у жителей разных возрастных групп в разных городах по месяцам.

В сервисе реализуем следующие обработчики:

* `POST /imports` Добавляет новую выгрузку с данными;
* `GET /imports/$import_id/citizens` Возвращает жителей указанной выгрузки;
* `PATCH /imports/$import_id/citizens/$citizen_id` Изменяет информацию о жителе (и его родственниках) в указанной выгрузке;
* `GET /imports/$import_id/citizens/birthdays` Вычисляет число подарков, которое приобретет каждый житель выгрузки своим родственникам (первого порядка), сгруппированное по месяцам;
* `GET /imports/$import_id/towns/stat/percentile/age` Вычисляет 50-й, 75-й и 99-й перцентили возрастов (полных лет) жителей по городам в указанной выборке.

## Кратко о том, какие инструменты выбирать?

Итак, пишем сервис на Python, используя знакомые фреймворки, библиотеки и СУБД.

В [4 лекции](https://habr.com/ru/company/yandex/blog/498856/#4) видеокурса рассказывается о различных СУБД и их особенностях. Для моей реализации я выбрал СУБД [PostgreSQL](https://www.postgresql.org/), зарекомендовавшую себя как надежное решение c отличной [документацией на русском языке](https://postgrespro.ru/docs), сильным русским сообществом (всегда можно найти ответ на вопрос на русском языке) и даже [бесплатными курсами](https://postgrespro.ru/education/courses). Реляционная модель достаточно универсальна и хорошо понятна многим разработчикам. Хотя то же самое можно было сделать на любой NoSQL СУБД, в этой статье будем рассматривать именно PostgreSQL.

Основная задача сервиса — передача данных по сети между БД и клиентами — не предполагает большой нагрузки на процессор, но требует возможности обрабатывать несколько запросов в один момент времени. В [10 лекции](https://habr.com/ru/company/yandex/blog/498856/#10) рассматривается асинхронный подход. Он позволяет эффективно обслуживать нескольких клиентов в рамках одного процесса ОС (в отличие, например, от используемой во Flask/Django pre-fork-модели, которая создает несколько процессов для обработки запросов от пользователей, каждый из них потребляет память, но простаивает большую часть времени). Поэтому в качестве библиотеки для написания сервиса я выбрал асинхронный [aiohttp](https://docs.aiohttp.org/en/stable/).

![Pre-fork и асинхронная модели обработки запросов](/img/orrjpnx6upvsipcqbsql7f36vzc.png)

В [5 лекции](https://habr.com/ru/company/yandex/blog/498856/#5) видеокурса рассказывается, что [SQLAlchemy](https://www.sqlalchemy.org/) позволяет декомпозировать сложные запросы на части, переиспользовать их, генерировать запросы с динамическим набором полей (например, PATCH-обработчик позволяет частичное обновление жителя с произвольными полями) и сосредоточиться непосредственно на бизнес-логике. С выполнением этих запросов и передачей данных быстрее всех справится драйвер [asyncpg](https://github.com/MagicStack/asyncpg), а подружить их поможет [asyncpgsa](https://asyncpgsa.readthedocs.io/en/latest/).

Мой любимый инструмент для управления состоянием БД и работы с миграциями — [Alembic](https://alembic.sqlalchemy.org/). Кстати, я недавно рассказывал о нем на [Moscow Python](https://www.youtube.com/watch?v=qrlTDNaUQ-Q&feature=youtu.be&t=5651).

Логику валидации получилось лаконично описать схемами [Marshmallow](https://marshmallow.readthedocs.io/en/stable/) (включая проверки на родственные связи). С помощью модуля [aiohttp-spec](https://github.com/maximdanilchenko/aiohttp-apispec) я связал aiohttp-обработчики и схемы для валидации данных, а бонусом получилось сгенерировать документацию в формате [Swagger](https://swagger.io/) и отобразить ее в [графическом интерфейсе](https://swagger.io/tools/swagger-ui/).

Для написания тестов я выбрал `pytest`, подробнее о нем — в [3 лекции](https://habr.com/ru/company/yandex/blog/498856/#3).

Для отладки и профилирования этого проекта я использовал отладчик PyCharm ([лекция 9](https://habr.com/ru/company/yandex/blog/498856/#9)).

В [7 лекции](https://habr.com/ru/company/yandex/blog/498856/#7) рассказывается, как на любом компьютере с [Docker](http://docker.com/) (и даже на разных ОС) можно запускать упакованное приложение без необходимости настраивать окружение для запуска и легко устанавливать/обновлять/удалять приложение на сервере.

Для деплоя я выбрал [Ansible](https://www.ansible.com/). Он позволяет декларативно описывать желаемое состояние сервера и его сервисов, работает по ssh и не требует специального софта.
