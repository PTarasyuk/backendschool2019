# Тестирование

Что нужно проверить в этом приложении?

* Во-первых, что обработчики отвечают требованиям и выполняют требуемую работу в окружении, максимально близком к боевому.
* Во-вторых, что миграции, которые изменяют состояние базы данных, работают без ошибок.
* В-третьих, есть ряд вспомогательных функций, которые тоже было бы правильно покрыть тестами.

Я решил воспользоваться [фреймворком pytest](https://docs.pytest.org/en/latest/) из-за его гибкости и простоты в использовании. Он предлагает мощный механизм подготовки окружения для тестов — [фикстуры](https://docs.pytest.org/en/latest/fixture.html), то есть функции с декоратором `pytest.mark.fixture`, названия которых можно указать параметром в тесте. Если pytest обнаружит в аннотации теста параметр с названием фикстуры, он выполнит эту фикстуру и передаст результат в значении этого параметра. А если фикстура является генератором, то параметр теста примет значение, возвращаемое `yield`, и после окончания теста выполнится вторая часть фикстуры, которая может очистить ресурсы или закрыть соединения.

Для большинства тестов нам потребуется база данных PostgreSQL. Чтобы изолировать тесты друг от друга, можно перед выполнением каждого теста создавать отдельную базу данных, а после выполнения — удалять ее.

??? example "Создаем базу данных фикстурой для каждого теста"

    ```python
    import os
    import uuid
    
    import pytest
    from sqlalchemy import create_engine
    from sqlalchemy_utils import create_database, drop_database
    from yarl import URL
    
    from analyzer.utils.pg import DEFAULT_PG_URL
    
    
    PG_URL = os.getenv('CI_ANALYZER_PG_URL', DEFAULT_PG_URL)
    
    
    @pytest.fixture
    def postgres():
        tmp_name = '.'.join([uuid.uuid4().hex, 'pytest'])
        tmp_url = str(URL(PG_URL).with_path(tmp_name))
        create_database(tmp_url)
    
        try:
            # Это значение будет иметь параметр postgres в функции-тесте
            yield tmp_url
        finally:
            drop_database(tmp_url)
    
    
    def test_db(postgres):
        """
        Пример теста, использующего PostgreSQL
        """
        engine = create_engine(postgres)
        assert engine.execute('SELECT 1').scalar() == 1
        engine.dispose()
    ```

C этой задачей здорово справился модуль [`sqlalchemy_utils`](https://sqlalchemy-utils.readthedocs.io/en/latest/), учитывающий особенности разных баз данных и драйверов. Например, PostgreSQL не разрешает выполнение `CREATE DATABASE` в блоке транзакции. При создании БД `sqlalchemy_utils` переводит `psycopg2` (который обычно выполняет все запросы в транзакции) в режим `autocommit`.

Другая важная особенность: если к PostgreSQL подключен хотя бы один клиент — базу данных нельзя удалить, а `sqlalchemy_utils` отключает всех клиентов перед удалением базы. БД будет успешно удалена, даже если зависнет какой-нибудь тест, имеющий активные подключения к ней.

PostgreSQL потребуется нам в разных состояниях: для тестирования миграций необходима чистая база данных, в то время как обработчики требуют, чтобы все миграции были применены. Изменять состояние базы данных можно программно с помощью команд Alembic, для их вызова требуется объект конфигурации Alembic.

??? example "Создаем фикстурой объект конфигурации Alembic"

    ```python
    from types import SimpleNamespace
    
    import pytest
    
    from analyzer.utils.pg import make_alembic_config
    
    
    @pytest.fixture()
    def alembic_config(postgres):
        cmd_options = SimpleNamespace(config='alembic.ini', name='alembic',
                                      pg_url=postgres, raiseerr=False, x=None)
        return make_alembic_config(cmd_options)
    ```

Обратите внимание, что у фикстуры `alembic_config` есть параметр `postgres` — `pytest` позволяет не только указывать зависимость теста от фикстур, но и зависимости между фикстурами.

Этот механизм позволяет гибко разделять логику и писать очень краткий и переиспользуемый код.

## Обработчики

Для тестирования обработчиков требуется база данных с созданными таблицами и типами данных. Чтобы применить миграции, необходимо программно вызвать команду `upgrade` Alembic. Для ее вызова потребуется объект с конфигурацией Alembic, который мы уже определили фикстурой alembic_config. База данных с миграциями выглядит как вполне самостоятельная сущность, и ее можно представить в виде фикстуры:

```python
from alembic.command import upgrade


@pytest.fixture
async def migrated_postgres(alembic_config, postgres):
    upgrade(alembic_config, 'head')
    # Возвращаем DSN базы данных, которая была смигрирована
    return postgres
```

Когда миграций в проекте становится много, их применение для каждого теста может занимать слишком много времени. Чтобы ускорить процесс, можно один раз [создать базу данных с миграциями](https://github.com/alvassin/alembic-quickstart/blob/master/tests/api/conftest.py#L10) и затем [использовать ее в качестве шаблона](https://github.com/alvassin/alembic-quickstart/blob/master/tests/api/conftest.py#L24).

Помимо базы данных для тестирования обработчиков, потребуется запущенное приложение, а также клиент, настроенный на работу с этим приложением. Чтобы приложение было легко тестировать, я вынес его создание в функцию `create_app`, которая принимает параметры для запуска: базу данных, порт для REST API и другие.

Аргументы для запуска приложения можно также представить в виде отдельной фикстуры. Для их создания потребуется определить свободный порт для запуска тестируемого приложения и адрес до смигрированной временной базы данных.

Для определения свободного порта я воспользовался фикстурой `aiomisc_unused_port` из пакета aiomisc.

Стандартная фикстура `aiohttp_unused_port` тоже вполне бы подошла, но она возвращает функцию для определения свободных портов, в то время как `aiomisc_unused_port` возвращает сразу номер порта. Для нашего приложения требуется определить только один свободный порт, поэтому я решил не писать лишнюю строчку кода с вызовом `aiohttp_unused_port`.

```python
@pytest.fixture
def arguments(aiomisc_unused_port, migrated_postgres):
    return parser.parse_args(
        [
            '--log-level=debug',
            '--api-address=127.0.0.1',
            f'--api-port={aiomisc_unused_port}',
            f'--pg-url={migrated_postgres}'
        ]
    )
```

Все тесты с обработчиками подразумевают запросы к REST API, работа напрямую с приложением `aiohttp` не требуется. Поэтому я сделал одну фикстуру, которая запускает приложение и с помощью фабрики `aiohttp_client` создает и возвращает подключенный к приложению стандартный тестовый клиент `aiohttp.test_utils.TestClient`.

```python
from analyzer.api.app import create_app


@pytest.fixture
async def api_client(aiohttp_client, arguments):
    app = create_app(arguments)
    client = await aiohttp_client(app, server_kwargs={
        'port': arguments.api_port
    })

    try:
        yield client
    finally:
        await client.close()
```

Теперь, если в параметрах теста указать фикстуру `api_client`, произойдет следующее:

1. Фикстура postgres создаст базу данных (зависимость для `migrated_postgres`).

2. Фикстура `alembic_config` создаст объект конфигурации Alembic, подключенный к временной базе данных (зависимость для `migrated_postgres`).

3. Фикстура `migrated_postgres` применит миграции (зависимость для arguments).

4. Фикстура `aiomisc_unused_port` обнаружит свободный порт (зависимость для `arguments`).

5. Фикстура `arguments` создаст аргументы для запуска (зависимость для `api_client`).

6. Фикстура `api_client` создаст и запустит приложение и вернет клиента для выполнения запросов.

7. Выполнится тест.

8. Фикстура `api_client` отключит клиента и остановит приложение.

9. Фикстура `postgres` удалит базу данных.

Фикстуры позволяют избежать дублирования кода, но помимо подготовки окружения в тестах есть еще одно потенциальное место, в котором будет очень много одинакового кода — запросы к приложению.

Во-первых, сделав запрос, мы ожидаем получить определенный HTTP-статус. Во-вторых, если статус совпадает с ожидаемым, то перед работой с данными необходимо убедиться, что они имеют правильный формат. Здесь легко ошибиться и написать обработчик, который делает правильные вычисления и **возвращает правильный результат, но не проходит автоматическую валидацию из-за неправильного формата ответа** (например, забыть обернуть ответ в словарь с ключом `data`). Все эти проверки можно было бы сделать в одном месте.

В модуле `analyzer.testing` я подготовил для каждого обработчика функцию-помощник, которая проверяет статус HTTP, а также формат ответа с помощью Marshmallow.

### `GET /imports/$import_id/citizens`

Я решил начать с обработчика, возвращающего жителей, потому что он очень полезен для проверки результатов работы других обработчиков, изменяющих состояние базы данных.

Я намеренно не использовал код, добавляющий данные в базу из обработчика POST `/imports`, хотя вынести его в отдельную функцию несложно. Код обработчиков имеет свойство меняться, а если в коде, добавляющем в базу, будет какая-либо ошибка, есть вероятность, что тест перестанет работать как задумано и неявно для разработчиков перестанет показывать ошибки.

Для этого теста я определил следующие наборы данных для тестирования:

* Выгрузка с несколькими родственниками. Проверяет, что для каждого жителя будет правильно сформирован список с идентификаторами родственников.

* Выгрузка с одним жителем без родственников. Проверяет, что поле `relatives` — пустой список (из-за `LEFT JOIN` в SQL-запросе список родственников может быть равен `[None]`).

* Выгрузка с жителем, который сам себе родственник.

* Пустая выгрузка. Проверяет, что обработчик разрешает добавить пустую выгрузку и не падает с ошибкой.

Чтобы запустить один и тот же тест отдельно на каждой выгрузке, я воспользовался еще одним очень мощным механизмом pytest — [параметризацией](https://docs.pytest.org/en/latest/parametrize.html). Этот механизм позволяет обернуть функцию-тест в декоратор `pytest.mark.parametrize` и описать в нем, какие параметры должна принимать функция-тест для каждого отдельного тестируемого случая.

??? tldr "Как параметризовать тест"

    ```python
    import pytest
    
    from analyzer.utils.testing import generate_citizen
    
    
    datasets = [
        # Житель с несколькими родственниками
        [
            generate_citizen(citizen_id=1, relatives=[2, 3]),
            generate_citizen(citizen_id=2, relatives=[1]),
            generate_citizen(citizen_id=3, relatives=[1])
        ],
    
        # Житель без родственников
        [
            generate_citizen(relatives=[])
        ],
    
        # Выгрузка с жителем, который сам себе родственник
        [
            generate_citizen(citizen_id=1, name='Джейн', gender='male',
                             birth_date='17.02.2020', relatives=[1])
        ],
    
        # Пустая выгрузка
        [],
    ]
    
    
    @pytest.mark.parametrize('dataset', datasets)
    async def test_get_citizens(api_client, dataset):
        """
        Этот тест будет вызван 4 раза, отдельно для каждого датасета
        """
    ```

Итак, тест добавит выгрузку в базу данных, затем с помощью запроса к обработчику получит информацию о жителях и сравнит эталонную выгрузку с полученной. Но как сравнить жителей?

Каждый житель состоит из скалярных полей и поля `relatives` — списка идентификаторов родственников. Список в Python — упорядоченный тип, и при сравнении порядок элементов каждого списка имеет значение, но при сравнении списков с родственниками порядок не должен иметь значение.

Если привести `relatives` к множеству перед сравнением, то при сравнении не получится обнаружить ситуацию, когда у одного из жителей в поле `relatives` есть дубли. Если отсортировать список с идентификаторами родственников, это позволит обойти проблему разного порядка идентификаторов родственников, но при этом обнаружить дубли.

При сравнении двух списков с жителями можно столкнуться с похожей проблемой: технически, порядок жителей в выгрузке не важен, но важно обнаружить, если в одной выгрузке будет два жителя с одинаковыми идентификаторами, а в другой нет. Так что помимо упорядочивания списка с родственниками `relatives` для каждого жителя необходимо упорядочить жителей в каждой выгрузке.

Так как задача сравнения жителей возникнет еще не раз, я реализовал две функции: одну для сравнения двух жителей, а вторую для сравнения двух списков с жителями:

??? tldr "Сравниваем жителей"

    ```python
    from typing import Iterable, Mapping
    
    
    def normalize_citizen(citizen):
        """
        Возвращает жителя с упорядоченным списком родственников
        """
        return {**citizen, 'relatives': sorted(citizen['relatives'])}
    
    
    def compare_citizens(left: Mapping, right: Mapping) -> bool:
        """
        Сравнивает двух жителей
        """
        return normalize_citizen(left) == normalize_citizen(right)
    
    
    def compare_citizen_groups(left: Iterable, right: Iterable) -> bool:
        """
        Упорядочивает списки с родственниками для каждого жителя, списки с жителями
        и сравнивает их
        """
        left = [normalize_citizen(citizen) for citizen in left]
        left.sort(key=lambda citizen: citizen['citizen_id'])
    
        right = [normalize_citizen(citizen) for citizen in right]
        right.sort(key=lambda citizen: citizen['citizen_id'])
    
        return left == right
    ```

Чтобы убедиться, что этот обработчик не возвращает жителей других выгрузок, я решил перед каждым тестом добавлять дополнительную выгрузку с одним жителем.

### `POST /imports`

Я определил следующие наборы данных для тестирования обработчика:

* **Корректные данные, ожидается успешное добавление в БД.**

    * Житель без родственников (самый простой).

        Обработчику необходимо добавить данные в две таблицы. Если не обрабатывается ситуация, когда у жителя нет родственников, будет выполнен пустой insert в таблицу родственных связей, что приведет к ошибке.

    * Житель с родственниками (более сложный, обычный).

        Проверяет, что обработчик корректно сохраняет данные и о жителе и его родственных связях.

    * Житель сам себе родственник.

        Про этот случай было много вопросов, поэтому в шутку решил добавить и его. :)

    * Выгрузка с максимального размера

        Проверяет, что aiohttp позволяет загружать такие объемы данных и что при большом количестве данных в PostgreSQL не отправляется больше 32 767 аргументов (обработчик должен выполнить несколько запросов).

    * Пустая выгрузка

        Обработчик должен учитывать такой случай и не падать, пытаясь выполнить пустой insert в таблицу с жителями.

* **Данные с ошибками, ожидаем HTTP-ответ `400: Bad Request`.**

    * Дата рождения некорректная (будущее время).

    * `citizen_id` в рамках выгрузки не уникален.

    * Родственная связь указана неверно (есть только от одного жителя к другому, но нет обратной).

    * У жителя указан несуществующий в выгрузке родственник.

    * Родственные связи не уникальны.

Если обработчик отработал успешно и данные были добавлены, необходимо получить добавленных в БД жителей и сравнить их с эталонной выгрузки. Для получения жителей я воспользовался уже протестированным обработчиком `GET /imports/$import_id/citizens`, а для сравнения — функцией `compare_citizen_groups`.

### `PATCH /imports/$import_id/citizens/$citizen_id`

Валидация данных во многом похожа на описанную в обработчике `POST /imports` с небольшими исключениями: есть только один житель и клиент может передать [только те поля, которые пожелает](https://developer.mozilla.org/ru/docs/Web/HTTP/Methods/PATCH).

Я решил использовать следующие наборы с некорректными данными, чтобы проверить, что обработчик вернет HTTP-ответ `400: Bad request`:

* Поле указано, но имеет некорректный тип и/или формат данных.

* Указана некорректная дата рождения (будущее время).

* Поле `relatives` содержит несуществующего в выгрузке родственника.

Также необходимо проверить, что обработчик корректно обновляет информацию о жителе и его родственниках.

Для этого создадим выгрузку с тремя жителями, два из которых — родственники, и отправим запрос с новыми значениями всех скалярных полей и новым идентификатором родственника в поле `relatives`.

Чтобы убедиться, что обработчик различает жителей разных выгрузок перед тестом (и, например, не изменит жителей с одинаковыми идентификаторами из другой выгрузки), я создал дополнительную выгрузку с тремя жителями, которые имеют такие же идентификаторы.

Обработчик должен сохранить новые значения скалярных полей, добавить нового указанного родственника и удалить связь со старым, не указанным родственником. Все изменения родственных связей должны быть двусторонними. Изменений в других выгрузках быть не должно.

Поскольку такой обработчик может быть подвержен состоянию гонки (это рассматривалось в разделе «Разработка»), я добавил [два дополнительных теста](https://github.com/alvassin/backendschool2019/blob/master/tests/api/test_update_race_condition.py). Один воспроизводит проблему с состоянием гонки (расширяет класс обработчика и убирает блокировку), второй доказывает, что проблема с состоянием гонки не воспроизводится.

### `GET /imports/$import_id/citizens/birthdays`

Для тестирования этого обработчика я выбрал следующие наборы данных:

* Выгрузка, в которой у жителя есть один родственник в одном месяце и два родственника в другом.

* Выгрузка с одним жителем без родственников. Проверяет, что обработчик не учитывает его при расчетах.

* Пустая выгрузка. Проверяет, что обработчик не упадет с ошибкой и вернет в ответе корректный словарь с 12 месяцами.

* Выгрузка с жителем, который сам себе родственник. Проверяет, что житель купит себе подарок в месяц своего рождения.

Обработчик должен возвращать в ответе все месяцы, даже если в эти месяцы нет дней рождений. Чтобы избежать дублирования, я сделал функцию, которой можно передать словарь, чтобы она дополнила его значениями для отсутствующих месяцев.

Чтобы убедиться, что обработчик различает жителей разных выгрузок, я добавил дополнительную выгрузку с двумя родственниками. Если обработчик по ошибке использует их при расчетах, то результаты будут некорректными и обработчик упадет с ошибкой.

### `GET /imports/$import_id/towns/stat/percentile/age`

Особенность этого теста в том, что результаты его работы зависят от текущего времени: возраст жителей вычисляется исходя из текущей даты. Чтобы результаты тестирования не менялись с течением времени, текущую дату, даты рождения жителей и ожидаемые результаты необходимо зафиксировать. Это позволит легко воспроизвести любые, даже краевые случаи.

Как лучше зафиксировать дату? В обработчике для вычисления возраста жителей используется PostgreSQL-функция [`AGE`](https://postgrespro.ru/docs/postgrespro/9.5/functions-datetime), принимающая первым параметром дату, для которой необходимо рассчитать возраст, а вторым — базовую дату (определена константой `TownAgeStatView.CURRENT_DATE`).

??? tldr "Подменяем базовую дату в обработчике на время теста"

    ```python
    from unittest.mock import patch
    
    import pytz
    
    CURRENT_DATE = datetime(2020, 2, 17, tzinfo=pytz.utc)
    
    
    @patch('analyzer.api.handlers.TownAgeStatView.CURRENT_DATE', new=CURRENT_DATE)
    async def test_get_ages(...):
        ...
    ```

Для тестирования обработчика я выбрал следующие наборы данных (для всех жителей указывал один город, потому что обработчик агрегирует результаты по городам):

* Выгрузка с несколькими жителями, у которых завтра день рождения (возраст — несколько лет и 364 дня). Проверяет, что обработчик использует в расчетах только количество полных лет.

* Выгрузка с жителем, у которого сегодня день рождения (возраст — ровно несколько лет). Проверяет краевой случай — возраст жителя, у которого сегодня день рождения, не должен рассчитаться как уменьшенный на 1 год.

* Пустая выгрузка. Обработчик не должен на ней падать.

Эталон для расчета перцентилей — `numpy` с линейной интерполяцией, и эталонные результаты для тестирования я рассчитал именно им.

Также нужно округлять дробные значения перцентилей до двух знаков после запятой. Если вы использовали в обработчике для округления PostgreSQL, а для расчета эталонных данных — Python, то могли заметить, что **округление в Python 3 и PostgreSQL может давать разные результаты**.

??? example "Например"

    ```text
    # Python 3
    round(2.5)
    > 2
    
    -- PostgreSQL
    SELECT ROUND(2.5)
    > 3
    ```

Дело в том, что Python использует банковское округление [до ближайшего четного](https://docs.python.org/3/library/functions.html#round), а PostgreSQL — математическое (half-up). В случае, если расчеты и округление производятся в PostgreSQL, было бы правильным в тестах также использовать математическое округление.

Сначала я описал наборы данных с датами рождения в текстовом формате, но читать тест в таком формате было неудобно: приходилось каждый раз вычислять в уме возраст каждого жителя, чтобы вспомнить, что проверяет тот или иной набор данных. Конечно, можно было обойтись комментариями в коде, но я решил пойти чуть дальше и написал функцию `age2date`, которая позволяет описать дату рождения в виде возраста: количества лет и дней.

??? example "Например, вот так"

    ```python
    import pytz
    
    from analyzer.utils.testing import generate_citizen
    
    
    CURRENT_DATE = datetime(2020, 2, 17, tzinfo=pytz.utc)
    
    def age2date(years: int, days: int = 0, base_date=CURRENT_DATE) -> str:
        birth_date = copy(base_date).replace(year=base_date.year - years)
        birth_date -= timedelta(days=days)
        return birth_date.strftime(BIRTH_DATE_FORMAT)
    
    # Сколько лет этому жителю? Посчитать несложно, но если их будет много?
    generate_citizen(birth_date='17.02.2009')
    
    # Жителю ровно 11 лет и у него сегодня день рождения
    generate_citizen(birth_date=age2date(years=11))
    ```

Чтобы убедиться, что обработчик различает жителей разных выгрузок, я добавил дополнительную выгрузку с одним жителем из другого города: если обработчик по ошибке использует его, в результатах появится лишний город и тест сломается.

!!! warning

    **Интересный факт:** когда я писал этот тест 29 февраля 2020 года, у меня внезапно перестали генерироваться выгрузки с жителями [из-за бага в Faker](https://github.com/joke2k/faker/issues/1123) (2020-й — високосный год, а другие годы, которые выбирал Faker, не всегда были високосными и в них не было 29 февраля). Не забывайте фиксировать даты и тестировать краевые случаи!

## Миграции

Код миграций на первый взгляд кажется очевидным и наименее подверженным ошибкам, зачем его тестировать? Это очень опасное заблуждение: самые коварные ошибки миграций могут проявить себя в самый неподходящий момент. Даже если они не испортят данные, то могут стать причиной лишнего даунтайма.

Существующая в проекте *initial* миграция изменяет структуру базы данных, но не изменяет данные. От каких типовых ошибок можно защититься в подобных миграциях?

* Метод `downgrade` не реализован или не удалены все созданные в миграции сущности (особенно это касается пользовательских типов данных, которые создаются автоматически при создании таблицы, я про них уже упоминал).

    Это приведет к тому, что миграцию нельзя будет применить два раза (применить-откатить-применить): при откате не будут удалены все созданные миграцией сущности, при повторном создании миграция пройдет с ошибкой — тип данных уже существует.

* Синтаксические ошибки и опечатки.

* Ошибки в связях миграций (цепочка нарушена).

Большинство этих ошибок обнаружит [stairway-тест](https://github.com/alvassin/backendschool2019/blob/master/tests/migrations/test_stairway.py). Его идея — применять миграции по одной, последовательно выполняя методы `upgrade`, `downgrade`, `upgrade` для каждой миграции. Такой тест достаточно один раз добавить в проект, он не требует поддержки и будет служить верой и правдой.

А вот если миграция, помимо структуры, изменяла бы данные, то потребовалось бы написать хотя бы один отдельный тест, проверяющий, что данные корректно изменяются в методе `upgrade` и возвращаются к изначальному состоянию в `downgrade`. На всякий случай: [проект с примерами тестирования разных миграций](https://github.com/alvassin/alembic-quickstart), который я подготовил для [доклада про Alembic](https://bit.ly/2UhmyyD) на Moscow Python.
